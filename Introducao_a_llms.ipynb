{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "262de988-08db-4f2b-85f9-061f63c8c70b",
   "metadata": {},
   "source": [
    "<h1/>Introdu√ß√£o a LLMs ü§ñ</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a2a372-b6a9-4843-85d9-f135dc553005",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<h3/>O que s√£o LLMs?</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7669fdfe-b621-49d7-adbe-95493271e407",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "LLMs(Large Language Models) s√£o algoritmos de intelig√™ncia artificial, que aplicam t√©cnicas de rede neurais para realiza√ß√£o de processamento da linguagem humana ou texto usando <a href=\"https://www.ibm.com/br-pt/think/topics/self-supervised-learning\"/>aprendizado autossupervisionado</a>. As principais tarefas que esses modelos realizam s√£o: Gera√ß√£o de texto, tradu√ß√£o, resumos, gera√ß√£o de imagem e chat-bots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8550e86-9170-4248-8c2e-1067d435c50f",
   "metadata": {},
   "source": [
    "A seguir uma imagem mostrando a evolu√ß√£o do surgimento de LLMs no mercado:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae948f1e-7629-4173-a13f-e245990cb87f",
   "metadata": {},
   "source": [
    "<img src=\"https://infohub.delltechnologies.com/static/media/13f83181-93ad-4024-a34b-26de431d4d17.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46ccb50-ddac-4a3b-8eb5-273c757041fa",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<h3>Como Funcionam?</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6582e15f-7e51-465f-a7b0-6618fd61b436",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Basicamente, os LLMs funcionam com o principio do <a href=\"https://www.ibm.com/br-pt/think/topics/deep-learning\"/>Deep Learning</a>, fazendo uso das arquiteturas de redes neurais para processamento da linguagem humana. Geralmente esses modelos s√£o treinados com grandes <a href=\"https://www.ibm.com/br-pt/think/topics/dataset\"/>datasets</a> usando a t√©cnica de aprendizado autossupervisionado, a base de suas funcionalidades ir√° variar com o relacionamento e padr√µes lingu√≠sticos presentes nos dados usados para seu treinamento. A arquitetura de um LLM consiste em v√°rias camadas, as principais sendo as camadas de avan√ßo(feedfoward layers), camadas de incorpora√ß√£o(embeddings layers) e as camadas de aten√ß√£o(attention layers)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c974ff-dbaf-4e4c-8f28-83059346f5bf",
   "metadata": {},
   "source": [
    "A seguir uma imagem contendo um diagrama de como as camadas se comportam:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3286a0-0129-40f8-a3ae-b69d87908d77",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<img src=\"https://media.geeksforgeeks.org/wp-content/uploads/20230531140926/Transformer-python-(1).png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51aa39d5-ec2e-4de5-8775-9581990be8a2",
   "metadata": {},
   "source": [
    "Outros componentes que influenciam na arquitetura dos LLMs s√£o:\n",
    "<ul/>\n",
    "    <li>Tamanho do modelo e quantidade de <a href=\"https://pt.dataconomy.com/2025/05/08/parametros-llm/\">par√¢metros</a></li>\n",
    "    <li>Representa√ß√£o do input</li>\n",
    "    <li>Efici√™ncia computacional</li>\n",
    "    <li>Mecanismos de auto-aten√ß√£o</li>\n",
    "    <li>Objetivos de treino</li>\n",
    "    <li>Decodifica√ß√£o e gera√ß√£o de output</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f576a4e-d3d8-4f76-8d72-b1d7614b5734",
   "metadata": {},
   "source": [
    "<h3>Aplica√ß√£o dos LLMs</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd09d68-f74f-4be3-9aa3-972a0096cf3f",
   "metadata": {},
   "source": [
    "Atualmente os LLMs exercem as seguintes tarefas:\n",
    "<ul>\n",
    "    <li>\n",
    "    <b/>Gera√ß√£o de C√≥digo:</b> Os LLMs conseguem gerar c√≥digos basedos na instru√ß√£o do usu√°rio para tarefas espec√≠ficas.\n",
    "    </li>\n",
    "    <li>\n",
    "    <b/>Debugging e Documenta√ß√£o:</b> Os mesmos podem ser utilizados para indentifica√ß√£o de erros em c√≥digo e automatiza√ß√£o de documenta√ß√µes de projetos.\n",
    "    </li>\n",
    "    <li>\n",
    "    <b/>Responder Perguntas:</b> O usu√°rio pode realizar perguntas simples ou complexas, gerando respostas com contextos concisos.\n",
    "    </li>\n",
    "    <li>\n",
    "    <b/>Tradu√ß√£o e Corre√ß√£o Ligu√≠stica:</b> Esses modelos tamb√©m realiza√ß√£o tradu√ß√µes e corre√ß√µes gramaticais na maioria das linguas.\n",
    "    </li>   \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee818d72-0e35-4e13-b0f9-da503c106797",
   "metadata": {},
   "source": [
    "Atualmente, existem diversas aplica√ß√µes no mercado que fazem uso de Modelos de Linguagem de Grande Escala (LLMs). A OpenAI √© uma das mais conhecidas, com o ChatGPT, mas n√£o √© a √∫nica a oferecer solu√ß√µes em larga escala baseadas nessa tecnologia. Outras empresas tamb√©m t√™m se destacado, como o Google, com o Gemini; a DeepSeek; e a Microsoft, com o Copilot. Al√©m disso, h√° aplica√ß√µes voltadas para prop√≥sitos espec√≠ficos, como o GitHub Copilot, focado em programa√ß√£o, e o DALL¬∑E, da pr√≥pria OpenAI, voltado para gera√ß√£o de imagens. Devido √† sua natureza adaptativa, a tend√™ncia √© que o uso de LLMs continue crescendo de forma significativa nos mais diversos setores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a71eca-19ec-4875-9fb4-877673189bf3",
   "metadata": {},
   "source": [
    "<h3>Exemplo Pr√°tico</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58effd84-d58d-476b-a345-c082e74f86d8",
   "metadata": {},
   "source": [
    "Nesse exemplo usaremos a biblioteca <a href=\"https://huggingface.co/transformers/v3.0.2/index.html\">Transformers</a> do <a href=\"https://huggingface.co/\">Hugginface</a> que √© uma plataforma colaborativa voltada pra IA, semelhante ao GitHub, nele temos uma vasta cole√ß√£o de modelos, datasets, entre outras informa√ß√µes sobre IA. para iniciarmos precisamos configurar o ambiente e instalar as depend√™ncias nescess√°rias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20c78575-aeec-4cf8-837d-d2580ef8ced5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://anu9rng:****@rb-artifactory.bosch.com/artifactory/api/pypi/python-virtual/simple\n",
      "Requirement already satisfied: transformers in c:\\users\\prg2ca\\desktop\\nova pasta (3)\\.env\\lib\\site-packages (4.52.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\prg2ca\\desktop\\nova pasta (3)\\.env\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\prg2ca\\desktop\\nova pasta (3)\\.env\\lib\\site-packages (from transformers) (0.32.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\prg2ca\\desktop\\nova pasta (3)\\.env\\lib\\site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\prg2ca\\desktop\\nova pasta (3)\\.env\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\prg2ca\\desktop\\nova pasta (3)\\.env\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\prg2ca\\desktop\\nova pasta (3)\\.env\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\prg2ca\\desktop\\nova pasta (3)\\.env\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\prg2ca\\desktop\\nova pasta (3)\\.env\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\prg2ca\\desktop\\nova pasta (3)\\.env\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\prg2ca\\desktop\\nova pasta (3)\\.env\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\prg2ca\\desktop\\nova pasta (3)\\.env\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\prg2ca\\desktop\\nova pasta (3)\\.env\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\prg2ca\\desktop\\nova pasta (3)\\.env\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\prg2ca\\desktop\\nova pasta (3)\\.env\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\prg2ca\\desktop\\nova pasta (3)\\.env\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\prg2ca\\desktop\\nova pasta (3)\\.env\\lib\\site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\prg2ca\\desktop\\nova pasta (3)\\.env\\lib\\site-packages (from requests->transformers) (2025.4.26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f6443c-7f06-406a-a46f-2633737a4852",
   "metadata": {},
   "source": [
    "Tamb√©m √© necess√°rio a instala√ß√£o do pytorch, a mesma √© uma biblioteca pra dessenvolvimento de IA, sendo uma das dep√™ndencias para rodar os LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d685a07-f416-4e5d-bb77-c213b5e69c00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://anu9rng:****@rb-artifactory.bosch.com/artifactory/api/pypi/python-virtual/simple, https://download.pytorch.org/whl/cu113\n",
      "Requirement already satisfied: torch in c:\\users\\prg2ca\\desktop\\nova pasta (3)\\.env\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\prg2ca\\desktop\\nova pasta (3)\\.env\\lib\\site-packages (0.22.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\prg2ca\\desktop\\nova pasta (3)\\.env\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\prg2ca\\desktop\\nova pasta (3)\\.env\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\prg2ca\\desktop\\nova pasta (3)\\.env\\lib\\site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\prg2ca\\desktop\\nova pasta (3)\\.env\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\prg2ca\\desktop\\nova pasta (3)\\.env\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\prg2ca\\desktop\\nova pasta (3)\\.env\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\prg2ca\\desktop\\nova pasta (3)\\.env\\lib\\site-packages (from torch) (2025.5.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\prg2ca\\desktop\\nova pasta (3)\\.env\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\prg2ca\\desktop\\nova pasta (3)\\.env\\lib\\site-packages (from torchvision) (2.2.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\prg2ca\\desktop\\nova pasta (3)\\.env\\lib\\site-packages (from torchvision) (11.2.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\prg2ca\\desktop\\nova pasta (3)\\.env\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\prg2ca\\desktop\\nova pasta (3)\\.env\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01cdbb6-2fb6-4a8c-9679-26132133e29c",
   "metadata": {},
   "source": [
    "Usaremos o GPT2 como exemplo para gera√ß√£o de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53ffc52c-23ee-40e4-a6f6-cc4fed1b4436",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Hello, I'm a language model, I'm a language model. In my mind, I'm doing the same thing as you. All these different people are thinking about the same thing.\\n\\nI'm not talking about what the computer program does. I'm talking about what I'm thinking about. I'm thinking about what my body is thinking about. I'm thinking about what I'm making it. I'm thinking about what I'm making it. What my body is doing. I'm thinking about what my body is thinking about. What's my body doing? What's my body doing? What's my body doing?\\n\\nLet's talk about this, I'm not a computer programmer. I'm not a software developer. I'm not a computer programmer. I'm not a language model. I'm not a language model. My body is thinking about what I'm doing. What is my body doing? What's my body doing? What's my body doing?\\n\\nNow, I'm not saying that this is a good thing. But if you want to get better at programming, you can get better at writing. You can get better at being human. You can get better at being human. And you can do that.\\n\\nThat means that you can learn to play guitar,\"},\n",
       " {'generated_text': 'Hello, I\\'m a language model, and I\\'m trying to understand what you\\'re saying. In English, I have two English words: \"l\" and \"es.\" In Dutch, I have two Dutch words: \"n\" (pronounced \"noor\"), and \"no.\" In English, I have two English words: \"t\" (pronounced \"tore\"), and \"nh.\" In French, I have two French words: \"n\" (pronounced \"nou\"), and \"n.\" In German, I have two German words: \"n\" (pronounced \"nh\"), and \"n.\" In German, I have two German words: \"n\" (pronounced \"nh\"), and \"n.\" In Italian, I have two Italian words: \"n\" (pronounced \"nuh\"), and \"n.\" In Russian, I have two Russian words: \"n\" (pronounced \"nuh\"), and \"n.\" In Spanish, I have two Spanish words: \"n\" (pronounced \"nuh\"), and \"n.\" In German, I have two German words: \"n\" (pronounced \"nuh\"), and \"n.\" In Italian, I have two Italian words: \"n\" (pronounced \"nuh\"), and \"'},\n",
       " {'generated_text': \"Hello, I'm a language model, so I don't get much of a chance to interact with objects. But I did find that I can do things like check the state of a specific object in an expression, check the state of a certain object in a function, etc. I find that it's something I can do just as well, but that's not really something I'm aware of.\\n\\nAs an interpreter, it's always nice to know that I can do something with my code. I can write things on the fly and write things in a way that I've never done before.\\n\\nHowever, in my opinion, one of the most important things I want to do is to write things that I see as things that you have to talk about. You have to tell me what I want to do, and I can't be sure if I'm actually doing any of that. I probably want to write something like this:\\n\\nfunction MyFunction ( value ) { return value ; }\\n\\nNow, you can't just write that, but you can do something like this:\\n\\nfunction MyFunction ( value ) { return value ; }\\n\\nI can do that in two ways. One way, I can write something like this:\\n\\nfunction MyFunction ( value ) {\"},\n",
       " {'generated_text': 'Hello, I\\'m a language model, a language model, a language model.\"'},\n",
       " {'generated_text': \"Hello, I'm a language model, not a toolkit.\\n\\nIn a nutshell, I need to give language models a set of properties that I could use to describe them in real life.\\n\\nIf I wanted to create a new variable named foo, I could do just that.\\n\\nHowever, the problem is that I'm not ready for most of the functions.\\n\\nIn this post, I'll show you how to create a new variable named foo and then define all the fields that you need.\\n\\nIf you haven't already, you can read about how to create and define variables in the next post.\\n\\nThe next post is going to cover how to create and define a variable named foo.\\n\\nIn this post, I'll show you how to create and define variables in the context of the language model.\\n\\nIn the next post, I'll show you how to create and define variables in the context of the Java language model.\\n\\nI've always been on the lookout for a good starting point for writing a language model, which is exactly what I'm going to do by using this tutorial.\\n\\nI'm quite happy with the results so far, and I hope you like it.\\n\\nI hope that this post will be useful.\\n\\nAdvertisements\"}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "import torch\n",
    "import os\n",
    "\n",
    "#Configura√ß√£o de proxy, mantenha-se fora do proxy antes de rodar\n",
    "os.environ['HTTP_PROXY'] = ''\n",
    "os.environ['HTTPS_PROXY'] = ''\n",
    "\n",
    "#A Classe pipeline abstrai conceitos, facilitando a conex√£o direta com huggin face e utiliza√ß√£o dos LLMs.\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "\n",
    "#Essa inicializa um gerador de n√∫meros pseudoaleat√≥rios.\n",
    "set_seed(42)\n",
    "\n",
    "#Aqui definimos o texto base, o cumprimento m√°ximo do texto que ser√° gerado e o numero de retornos.\n",
    "generator(\"Hello, I'm a language model,\", max_length=30, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993aac26-8563-4642-aafa-c9d1b1bbbf70",
   "metadata": {},
   "source": [
    "Isso √© um exemplo b√°sico de utiliza√ß√£o, podendo ser adaptado para diversas tarefas e casos de uso por meio de fine tuning, por√©m isso requer uso de um bom hardware e principalmente uma boa GPU, para realiza√ß√£o de treinamentos mais espec√≠ficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9c2f84-428f-4d53-b00d-68e11f4d1ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4d68ab1-2c86-473d-b42a-dc3079b62f44",
   "metadata": {},
   "source": [
    "<h3>Benef√≠cios dos LLM</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac7d64e-9c19-4793-854c-ce27369a6d69",
   "metadata": {},
   "source": [
    "Os LLMs (Modelos de Linguagem de Grande Escala) s√£o capazes de realizar o <a href=\"https://www.ibm.com/br-pt/think/topics/zero-shot-learning\">aprendizado zero-shot</a>. Isso significa que conseguem generalizar tarefas para as quais n√£o foram explicitamente treinados, permitindo que se adaptem a novos cen√°rios sem a necessidade de treinamento adicional.\n",
    "Outro benef√≠cio importante √© a capacidade de manipular e compreender grandes volumes de dados, o que se aplica, por exemplo, √† tradu√ß√£o de idiomas e √† gera√ß√£o de resumos de documentos.\n",
    "Al√©m disso, os LLMs podem passar por <a href=\"http://ibm.com/br-pt/think/topics/fine-tuning\">fine-tuning</a> com conjuntos de dados espec√≠ficos, o que permite que se mantenham em constante evolu√ß√£o e adapta√ß√£o a diferentes casos de uso na ind√∫stria.\n",
    "Por fim, esses modelos automatizam uma ampla variedade de tarefas, como gera√ß√£o de c√≥digo e cria√ß√£o de conte√∫do, otimizando tempo e reduzindo a necessidade de m√£o de obra em atividades repetitivas, permitindo que os recursos humanos sejam direcionados a demandas mais estrat√©gicas e espec√≠ficas dentro de um projeto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74087c1d-ba31-4c87-90c8-9417b82d299d",
   "metadata": {},
   "source": [
    "<h3>Conclus√£o</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1aaa83-1d9f-4ac3-a0c8-15b7461fa8ed",
   "metadata": {},
   "source": [
    "Diante dos t√≥picos abordados, √© poss√≠vel afirmar com seguran√ßa que os LLMs (Modelos de Linguagem de Grande Escala) j√° se tornaram uma parte fundamental dos avan√ßos tecnol√≥gicos na ind√∫stria. Sua presen√ßa √© cada vez mais evidente em solu√ß√µes inovadoras, integrando-se a fluxos de trabalho, produtos e servi√ßos de maneira estrat√©gica.\n",
    "A tend√™ncia √© de avan√ßos cont√≠nuos e cada vez mais expressivos nessa tecnologia. Praticamente todas as big techs ‚Äî como Google, Microsoft, Meta, Amazon e OpenAI ‚Äî j√° desenvolvem e oferecem solu√ß√µes baseadas em LLMs, investindo pesadamente em pesquisa e desenvolvimento para ampliar a capacidade e efici√™ncia desses modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce212121-0427-437d-98f2-5f3645c68c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
