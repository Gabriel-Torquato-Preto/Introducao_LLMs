{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gabriel-Torquato-Preto/Introducao_LLMs/blob/main/Introducao_a_llms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "262de988-08db-4f2b-85f9-061f63c8c70b",
      "metadata": {
        "id": "262de988-08db-4f2b-85f9-061f63c8c70b"
      },
      "source": [
        "<h1/>Introdu√ß√£o a LLMs ü§ñ</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57a2a372-b6a9-4843-85d9-f135dc553005",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "57a2a372-b6a9-4843-85d9-f135dc553005"
      },
      "source": [
        "<h3/>O que s√£o LLMs?</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7669fdfe-b621-49d7-adbe-95493271e407",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "7669fdfe-b621-49d7-adbe-95493271e407"
      },
      "source": [
        "LLMs(Large Language Models) s√£o algoritmos de intelig√™ncia artificial, que aplicam t√©cnicas de rede neurais para realiza√ß√£o de processamento da linguagem humana ou texto usando <a href=\"https://www.ibm.com/br-pt/think/topics/self-supervised-learning\"/>aprendizado autossupervisionado</a>. As principais tarefas que esses modelos realizam s√£o: Gera√ß√£o de texto, tradu√ß√£o, resumos, gera√ß√£o de imagem e chat-bots."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8550e86-9170-4248-8c2e-1067d435c50f",
      "metadata": {
        "id": "d8550e86-9170-4248-8c2e-1067d435c50f"
      },
      "source": [
        "A seguir uma imagem mostrando a evolu√ß√£o do surgimento de LLMs no mercado:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae948f1e-7629-4173-a13f-e245990cb87f",
      "metadata": {
        "id": "ae948f1e-7629-4173-a13f-e245990cb87f"
      },
      "source": [
        "<img src=\"https://infohub.delltechnologies.com/static/media/13f83181-93ad-4024-a34b-26de431d4d17.png\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e46ccb50-ddac-4a3b-8eb5-273c757041fa",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "e46ccb50-ddac-4a3b-8eb5-273c757041fa"
      },
      "source": [
        "<h3>Como Funcionam?</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6582e15f-7e51-465f-a7b0-6618fd61b436",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "6582e15f-7e51-465f-a7b0-6618fd61b436"
      },
      "source": [
        "Basicamente, os LLMs funcionam com o principio do <a href=\"https://www.ibm.com/br-pt/think/topics/deep-learning\"/>Deep Learning</a>, fazendo uso das arquiteturas de redes neurais para processamento da linguagem humana. Geralmente esses modelos s√£o treinados com grandes <a href=\"https://www.ibm.com/br-pt/think/topics/dataset\"/>datasets</a> usando a t√©cnica de aprendizado autossupervisionado, a base de suas funcionalidades ir√° variar com o relacionamento e padr√µes lingu√≠sticos presentes nos dados usados para seu treinamento. A arquitetura de um LLM consiste em v√°rias camadas, as principais sendo as camadas de avan√ßo(feedfoward layers), camadas de incorpora√ß√£o(embeddings layers) e as camadas de aten√ß√£o(attention layers)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93c974ff-dbaf-4e4c-8f28-83059346f5bf",
      "metadata": {
        "id": "93c974ff-dbaf-4e4c-8f28-83059346f5bf"
      },
      "source": [
        "A seguir uma imagem contendo um diagrama de como as camadas se comportam:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e3286a0-0129-40f8-a3ae-b69d87908d77",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "2e3286a0-0129-40f8-a3ae-b69d87908d77"
      },
      "source": [
        "<img src=\"https://media.geeksforgeeks.org/wp-content/uploads/20230531140926/Transformer-python-(1).png\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51aa39d5-ec2e-4de5-8775-9581990be8a2",
      "metadata": {
        "id": "51aa39d5-ec2e-4de5-8775-9581990be8a2"
      },
      "source": [
        "Outros componentes que influenciam na arquitetura dos LLMs s√£o:\n",
        "<ul/>\n",
        "    <li>Tamanho do modelo e quantidade de <a href=\"https://pt.dataconomy.com/2025/05/08/parametros-llm/\">par√¢metros</a></li>\n",
        "    <li>Representa√ß√£o do input</li>\n",
        "    <li>Efici√™ncia computacional</li>\n",
        "    <li>Mecanismos de auto-aten√ß√£o</li>\n",
        "    <li>Objetivos de treino</li>\n",
        "    <li>Decodifica√ß√£o e gera√ß√£o de output</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f576a4e-d3d8-4f76-8d72-b1d7614b5734",
      "metadata": {
        "id": "6f576a4e-d3d8-4f76-8d72-b1d7614b5734"
      },
      "source": [
        "<h3>Aplica√ß√£o dos LLMs</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecd09d68-f74f-4be3-9aa3-972a0096cf3f",
      "metadata": {
        "id": "ecd09d68-f74f-4be3-9aa3-972a0096cf3f"
      },
      "source": [
        "Atualmente os LLMs exercem as seguintes tarefas:\n",
        "<ul>\n",
        "    <li>\n",
        "    <b/>Gera√ß√£o de C√≥digo:</b> Os LLMs conseguem gerar c√≥digos basedos na instru√ß√£o do usu√°rio para tarefas espec√≠ficas.\n",
        "    </li>\n",
        "    <li>\n",
        "    <b/>Debugging e Documenta√ß√£o:</b> Os mesmos podem ser utilizados para indentifica√ß√£o de erros em c√≥digo e automatiza√ß√£o de documenta√ß√µes de projetos.\n",
        "    </li>\n",
        "    <li>\n",
        "    <b/>Responder Perguntas:</b> O usu√°rio pode realizar perguntas simples ou complexas, gerando respostas com contextos concisos.\n",
        "    </li>\n",
        "    <li>\n",
        "    <b/>Tradu√ß√£o e Corre√ß√£o Ligu√≠stica:</b> Esses modelos tamb√©m realiza√ß√£o tradu√ß√µes e corre√ß√µes gramaticais na maioria das linguas.\n",
        "    </li>   \n",
        "</ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee818d72-0e35-4e13-b0f9-da503c106797",
      "metadata": {
        "id": "ee818d72-0e35-4e13-b0f9-da503c106797"
      },
      "source": [
        "Atualmente, existem diversas aplica√ß√µes no mercado que fazem uso de Modelos de Linguagem de Grande Escala (LLMs). A OpenAI √© uma das mais conhecidas, com o ChatGPT, mas n√£o √© a √∫nica a oferecer solu√ß√µes em larga escala baseadas nessa tecnologia. Outras empresas tamb√©m t√™m se destacado, como o Google, com o Gemini; a DeepSeek; e a Microsoft, com o Copilot. Al√©m disso, h√° aplica√ß√µes voltadas para prop√≥sitos espec√≠ficos, como o GitHub Copilot, focado em programa√ß√£o, e o DALL¬∑E, da pr√≥pria OpenAI, voltado para gera√ß√£o de imagens. Devido √† sua natureza adaptativa, a tend√™ncia √© que o uso de LLMs continue crescendo de forma significativa nos mais diversos setores."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74a71eca-19ec-4875-9fb4-877673189bf3",
      "metadata": {
        "id": "74a71eca-19ec-4875-9fb4-877673189bf3"
      },
      "source": [
        "<h3>Exemplo Pr√°tico</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58effd84-d58d-476b-a345-c082e74f86d8",
      "metadata": {
        "id": "58effd84-d58d-476b-a345-c082e74f86d8"
      },
      "source": [
        "Nesse exemplo usaremos a biblioteca <a href=\"https://huggingface.co/transformers/v3.0.2/index.html\">Transformers</a> do <a href=\"https://huggingface.co/\">Hugginface</a> que √© uma plataforma colaborativa voltada pra IA, semelhante ao GitHub, nele temos uma vasta cole√ß√£o de modelos, datasets, entre outras informa√ß√µes sobre IA. Para iniciarmos precisamos configurar o ambiente e instalar as depend√™ncias nescess√°rias.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20c78575-aeec-4cf8-837d-d2580ef8ced5",
      "metadata": {
        "scrolled": true,
        "id": "20c78575-aeec-4cf8-837d-d2580ef8ced5"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86f6443c-7f06-406a-a46f-2633737a4852",
      "metadata": {
        "id": "86f6443c-7f06-406a-a46f-2633737a4852"
      },
      "source": [
        "Tamb√©m √© necess√°rio a instala√ß√£o do pytorch, a mesma √© uma biblioteca pra dessenvolvimento de IA, sendo uma das dep√™ndencias para rodar os LLMs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d685a07-f416-4e5d-bb77-c213b5e69c00",
      "metadata": {
        "scrolled": true,
        "id": "5d685a07-f416-4e5d-bb77-c213b5e69c00"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a01cdbb6-2fb6-4a8c-9679-26132133e29c",
      "metadata": {
        "id": "a01cdbb6-2fb6-4a8c-9679-26132133e29c"
      },
      "source": [
        "Usaremos o GPT2 como exemplo para gera√ß√£o de texto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53ffc52c-23ee-40e4-a6f6-cc4fed1b4436",
      "metadata": {
        "id": "53ffc52c-23ee-40e4-a6f6-cc4fed1b4436"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline, set_seed\n",
        "import torch\n",
        "\n",
        "#A Classe pipeline abstrai conceitos, facilitando a conex√£o direta com huggin face e utiliza√ß√£o dos LLMs.\n",
        "generator = pipeline('text-generation', model='gpt2')\n",
        "\n",
        "#Essa seed inicializa um gerador de n√∫meros pseudoaleat√≥rios.\n",
        "set_seed(42)\n",
        "\n",
        "#Aqui definimos o texto base, o cumprimento m√°ximo do texto que ser√° gerado e o numero de retornos.\n",
        "generator(\"Hello, I'm a language model,\", max_length=30, num_return_sequences=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "993aac26-8563-4642-aafa-c9d1b1bbbf70",
      "metadata": {
        "id": "993aac26-8563-4642-aafa-c9d1b1bbbf70"
      },
      "source": [
        "Isso √© um exemplo b√°sico de utiliza√ß√£o, podendo ser adaptado para diversas tarefas e casos de uso por meio de fine tuning, por√©m isso requer uso de um bom hardware e principalmente uma boa GPU, para realiza√ß√£o de treinamentos mais espec√≠ficos."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4d68ab1-2c86-473d-b42a-dc3079b62f44",
      "metadata": {
        "id": "b4d68ab1-2c86-473d-b42a-dc3079b62f44"
      },
      "source": [
        "<h3>Benef√≠cios dos LLM</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ac7d64e-9c19-4793-854c-ce27369a6d69",
      "metadata": {
        "id": "9ac7d64e-9c19-4793-854c-ce27369a6d69"
      },
      "source": [
        "Os LLMs (Modelos de Linguagem de Grande Escala) s√£o capazes de realizar o <a href=\"https://www.ibm.com/br-pt/think/topics/zero-shot-learning\">aprendizado zero-shot</a>. Isso significa que conseguem generalizar tarefas para as quais n√£o foram explicitamente treinados, permitindo que se adaptem a novos cen√°rios sem a necessidade de treinamento adicional.\n",
        "Outro benef√≠cio importante √© a capacidade de manipular e compreender grandes volumes de dados, o que se aplica, por exemplo, √† tradu√ß√£o de idiomas e √† gera√ß√£o de resumos de documentos.\n",
        "Al√©m disso, os LLMs podem passar por <a href=\"http://ibm.com/br-pt/think/topics/fine-tuning\">fine-tuning</a> com conjuntos de dados espec√≠ficos, o que permite que se mantenham em constante evolu√ß√£o e adapta√ß√£o a diferentes casos de uso na ind√∫stria.\n",
        "Por fim, esses modelos automatizam uma ampla variedade de tarefas, como gera√ß√£o de c√≥digo e cria√ß√£o de conte√∫do, otimizando tempo e reduzindo a necessidade de m√£o de obra em atividades repetitivas, permitindo que os recursos humanos sejam direcionados a demandas mais estrat√©gicas e espec√≠ficas dentro de um projeto."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74087c1d-ba31-4c87-90c8-9417b82d299d",
      "metadata": {
        "id": "74087c1d-ba31-4c87-90c8-9417b82d299d"
      },
      "source": [
        "<h3>Conclus√£o</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b1aaa83-1d9f-4ac3-a0c8-15b7461fa8ed",
      "metadata": {
        "id": "7b1aaa83-1d9f-4ac3-a0c8-15b7461fa8ed"
      },
      "source": [
        "Diante dos t√≥picos abordados, √© poss√≠vel afirmar com seguran√ßa que os LLMs (Modelos de Linguagem de Grande Escala) j√° se tornaram uma parte fundamental dos avan√ßos tecnol√≥gicos na ind√∫stria. Sua presen√ßa √© cada vez mais evidente em solu√ß√µes inovadoras, integrando-se a fluxos de trabalho, produtos e servi√ßos de maneira estrat√©gica.\n",
        "A tend√™ncia √© de avan√ßos cont√≠nuos e cada vez mais expressivos nessa tecnologia. Praticamente todas as big techs ‚Äî como Google, Microsoft, Meta, Amazon e OpenAI ‚Äî j√° desenvolvem e oferecem solu√ß√µes baseadas em LLMs, investindo pesadamente em pesquisa e desenvolvimento para ampliar a capacidade e efici√™ncia desses modelos."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}